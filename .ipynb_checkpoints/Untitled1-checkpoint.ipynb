{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "def log(t):\n",
    "    ts = datetime.now().strftime('%H:%M:%S')\n",
    "    print('{} :: {}'.format(ts, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRING_SUMMER = 'spring-summer'\n",
    "FALL_WINTER = 'fall-winter'\n",
    "SEASON_TEMPLATE = 'https://www.supremecommunity.com/season/{}{}/droplists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_links(season, year):\n",
    "    response = requests.get(SEASON_TEMPLATE.format(season, year))\n",
    "    doc = pq(response.content)\n",
    "    links = [('https://www.supremecommunity.com' + pq(block).attr('href'), pq(block).attr('href')[-11:-1])\n",
    "            for block in doc('a.block')]\n",
    "    links.reverse()\n",
    "    return links\n",
    "\n",
    "def get_week_tees_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    doc = pq(response.content)\n",
    "    return [pq(card).find('h2').text() \n",
    "            for card in doc('.card.card-2') \n",
    "            if pq(card).find('.category').text() == 't-shirts']\n",
    "\n",
    "def get_season_tees(season, year):\n",
    "    return [{\"week\": link[1],\"tees\":get_week_tees_from_url(link[0])} \n",
    "            for link in get_season_links(season,year)]\n",
    "\n",
    "def get_all_tees():\n",
    "    return [get_season_tees(s,y) for y in [2017,2018,2019] for s in [SPRING_SUMMER, FALL_WINTER]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tees = get_all_tees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_to_stockx_name(sc):\n",
    "    sc = sc.replace(' ', '-')\n",
    "    sc = sc.replace('L/S', 'ls')\n",
    "    sc = sc.replace('/', '-')\n",
    "    sc = sc.replace('™', '-')\n",
    "    sc = sc.replace('®', '-')\n",
    "    sc = sc.replace('&', '-')\n",
    "    sc = sc.replace('--', '-')\n",
    "    sc = sc.replace('.','')\n",
    "    return sc + '-black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:22:55 :: Retrieving search results for Sade-Tee-black\n",
      "17:22:56 :: Retrieving search results for Elephant-Tee-black\n",
      "17:22:56 :: Retrieving search results for Abstract-Tee-black\n",
      "17:22:56 :: Retrieving search results for Eternal-Tee-black\n",
      "17:22:56 :: Retrieving search results for FTP-Tee-black\n",
      "17:22:56 :: Retrieving search results for Automatic-Tee-black\n",
      "17:22:57 :: Retrieving search results for Joe-Roberts-Swirl-Tee-black\n",
      "17:22:57 :: Retrieving search results for Dream-Tee-black\n",
      "17:22:57 :: Retrieving search results for Been-Hit-ls-Tee-black\n",
      "17:22:57 :: Retrieving search results for Larry-Clark-Girl-Tee-black\n",
      "17:22:57 :: Retrieving search results for Mirage-Tee-black\n",
      "17:22:58 :: Retrieving search results for Digi-Tee-black\n",
      "17:22:58 :: Retrieving search results for Punany-Train-Tee-black\n",
      "17:22:58 :: Retrieving search results for Super-Supreme-Tee-black\n",
      "17:22:59 :: Retrieving search results for Undercover-Lover-Tee-black\n",
      "17:22:59 :: Retrieving search results for Orgy-Tee-black\n",
      "17:22:59 :: Retrieving search results for Go-Fuck-Yourself-Tee-black\n",
      "17:22:59 :: Retrieving search results for Buy-Off-The-Bar-Tee-black\n",
      "17:22:59 :: Retrieving search results for Know-Your-Rights-Tee-black\n",
      "17:23:00 :: Retrieving search results for Nas-Tee-black\n",
      "17:23:00 :: Retrieving search results for Crash-Tee-black\n",
      "17:23:00 :: Retrieving search results for Dollar-Tee-black\n",
      "17:23:01 :: Retrieving search results for DNA-Tee-black\n",
      "17:23:01 :: Retrieving search results for Heart-Tee-black\n",
      "17:23:01 :: Retrieving search results for Gonz-Heads-Tee-black\n",
      "17:23:02 :: Retrieving search results for Fuck-With-Your-Head-Tee-black\n",
      "17:23:02 :: Retrieving search results for Venus-Tee-black\n",
      "17:23:03 :: Retrieving search results for Bloom-ls-Tee-black\n",
      "17:23:03 :: Retrieving search results for Kiss-Tee-black\n",
      "17:23:03 :: Retrieving search results for Nas-Tee-black\n",
      "17:23:04 :: Retrieving search results for Crash-Tee-black\n",
      "17:23:04 :: Retrieving search results for Dollar-Tee-black\n",
      "17:23:04 :: Retrieving search results for DNA-Tee-black\n",
      "17:23:04 :: Retrieving search results for Heart-Tee-black\n",
      "17:23:05 :: Retrieving search results for Gonz-Heads-Tee-black\n",
      "17:23:05 :: Retrieving search results for Fuck-With-Your-Head-Tee-black\n",
      "17:23:05 :: Retrieving search results for Venus-Tee-black\n",
      "17:23:06 :: Retrieving search results for Bloom-ls-Tee-black\n",
      "17:23:06 :: Retrieving search results for Kiss-Tee-black\n",
      "17:23:06 :: Retrieving search results for Plant-Tee-black\n",
      "17:23:07 :: Retrieving search results for Friends-Tee-black\n",
      "17:23:07 :: Retrieving search results for Candle-Tee-black\n",
      "17:23:07 :: Retrieving search results for Piss-Christ-Tee-black\n",
      "17:23:07 :: Retrieving search results for Madonna--Child-Tee-black\n",
      "17:23:08 :: Retrieving search results for Decline-of-Western-Civilization-Tee-black\n",
      "17:23:08 :: Retrieving search results for Scarface-Split-Tee-black\n",
      "17:23:08 :: Retrieving search results for Scarface-Blimp-Tee-black\n",
      "17:23:08 :: Retrieving search results for Scarface-Friend-Tee-black\n",
      "17:23:08 :: Retrieving search results for Scarface-Shower-Tee-black\n",
      "17:23:09 :: Retrieving search results for AKIRA-Supreme-Pill-Tee-black\n",
      "17:23:09 :: Retrieving search results for AKIRA-Supreme-Arm-Tee-black\n",
      "17:23:09 :: Retrieving search results for AKIRA-Supreme-Yamagata-Tee-black\n",
      "17:23:09 :: Retrieving search results for AKIRA-Supreme-Syringe-Tee-black\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-8235ff386e3f>\u001b[0m in \u001b[0;36mget_first_result\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://stockx.com/api/browse?&_search=AKIRA-Supreme-Syringe-Tee-black",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-c43c86d9254e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tees'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc_to_stockx_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_first_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Products'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'market'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'averageDeadstockPrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-187-8235ff386e3f>\u001b[0m in \u001b[0;36mget_first_result\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Product detail retrieval failed [{}] : {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Failed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'error'"
     ]
    }
   ],
   "source": [
    "d = Downloader()\n",
    "\n",
    "with open('supreme_tshirts.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['name', 'release date', 'stockx search', 'price']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for season in all_tees:\n",
    "        for date in season:\n",
    "            for t in date['tees']:\n",
    "                search = sc_to_stockx_name(t)\n",
    "                first = d.get_first_result(search)\n",
    "                try:\n",
    "                    price = first['Products'][0]['market']['averageDeadstockPrice']\n",
    "                except (AttributeError, IndexError):\n",
    "                    price = \"Bad search\"\n",
    "                \n",
    "                writer.writerow({'name': t, 'release date': date['week'], 'stockx search': search, 'price': price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downloader(threading.Thread):\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.S = requests.Session()\n",
    "        self.S.headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',\n",
    "            'content-type': 'application/json'\n",
    "        }\n",
    "        self.rawdetails = {}\n",
    "        \n",
    "    def get_first_result(self, query):\n",
    "        log('Retrieving search results for {}'.format(query))\n",
    "        \n",
    "        r = self.S.request(\n",
    "            method='get',\n",
    "            url='https://stockx.com/api/browse?&_search={}'.format(query),\n",
    "        )\n",
    "        try:\n",
    "            j = r.json()\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            log('Product detail retrieval failed [{}]'.format(r.status_code))\n",
    "            return 'Failed'\n",
    "        try:\n",
    "            r.raise_for_status()\n",
    "        except requests.exceptions.HTTPError:\n",
    "            log('Product detail retrieval failed [{}] : {}'.format(r.status_code, j['error']))\n",
    "            return 'Failed'\n",
    "        return j\n",
    "    \n",
    "    def get_raw_details(self, product):\n",
    "        log('Retrieving raw details for {}'.format(product))\n",
    "        \n",
    "        r = self.S.request(\n",
    "            method='get',\n",
    "            url='https://stockx.com/api/products/{}?includes=market'.format(product),\n",
    "            params = {\n",
    "            }\n",
    "        )\n",
    "        try: \n",
    "            j = r.json()\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            log('Product detail retrieval failed [{}]'.format(r.status_code))\n",
    "            return False\n",
    "        try:\n",
    "            r.raise_for_status()\n",
    "        except requests.exceptions.HTTPError:\n",
    "            log('Product detail retrieval failed [{}] : {}'.format(r.status_code, j['error']))\n",
    "            return False\n",
    "        self.rawdetails = j\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCT = 'supreme-motion-logo-tee-ss20-white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:24:44 :: Retrieving raw details for supreme-motion-logo-tee-ss20-white\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get_raw_details(PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:36:08 :: Retrieving search results for yeezy\n"
     ]
    }
   ],
   "source": [
    "yeezy_query = d.get_first_result(\"yeezy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeezy_query['Products'][0]['market']['averageDeadstockPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:24:46 :: Retrieving search results for supreme-cloud-tee\n"
     ]
    }
   ],
   "source": [
    "cloud = d.get_first_result(\"supreme-cloud-tee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud['Products'][0]['market']['averageDeadstockPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
